{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t18ILM_v3tNm"
      },
      "source": [
        "# **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uch5Dn5q5my",
        "outputId": "50ea5860-180a-4d5d-f094-7befc7bc20e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faker\n",
            "  Downloading Faker-15.3.2-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.1 in /usr/local/lib/python3.7/dist-packages (from faker) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-15.3.2\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "from google.colab import  drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "!pip install faker\n",
        "from faker import Faker\n",
        "faker = Faker()\n",
        "import random\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X5hHhsna4D30"
      },
      "source": [
        "# **DATA VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhaWybAo0XOi"
      },
      "outputs": [],
      "source": [
        "# VARIABLES TO BE FILLED\n",
        "property_price = None\n",
        "property_type = None\n",
        "property_area_sqft = None\n",
        "property_area_sqm = None\n",
        "property_bedrooms = None\n",
        "property_bathrooms = None\n",
        "property_id = None\n",
        "property_listing_date = None\n",
        "property_location = None\n",
        "property_desc = None\n",
        "property_amenities = None\n",
        "\n",
        "agent_name = None\n",
        "agent_phone = None\n",
        "agent_email = None\n",
        "agent_whatsapp = None\n",
        "\n",
        "broker_name = None\n",
        "broker_listings = None\n",
        "broker_address = None\n",
        "broker_phone = None\n",
        "\n",
        "project_name = None\n",
        "project_location = None\n",
        "project_head_office = None\n",
        "project_total_units = None\n",
        "project_photo = None"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7JUSHOYBxrqG"
      },
      "source": [
        "# **LOOPING THROUGH ALL PAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yCT6H5vXqFCF",
        "outputId": "95ddf943-c104-4b7b-e43d-f65b0010bc66"
      },
      "outputs": [],
      "source": [
        "property_data = []\n",
        "agent_data = []\n",
        "broker_data = []\n",
        "project_data = []\n",
        "user_data = []\n",
        "review_data = []\n",
        "\n",
        "# SET CONDITIONS FOR LOOP\n",
        "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36 Edg/106.0.1370.42'}\n",
        "\n",
        "max_listing_date = 14\n",
        "pageno = 1\n",
        "listing_date_below_14 = True\n",
        "\n",
        "# #####                                  #######\n",
        "# #####  LOOP THROUGH ALL PAGES          ######\n",
        "# #####                                  #######\n",
        "\n",
        "\n",
        "\n",
        "while listing_date_below_14:\n",
        "  # GET PAGE URL\n",
        "  page_url = \"https://www.propertyfinder.eg/en/search?c=1&ob=nd&page=\"+str(pageno)+\"&pt=3000000\"\n",
        "  \n",
        "  # GET PAGE RESPONSE\n",
        "  page_response = requests.get(page_url, headers=HEADERS)\n",
        "  \n",
        "  # GET PAGE SOUP\n",
        "  page_soup = BeautifulSoup(page_response.content)\n",
        "  \n",
        "  # GET FIRST LISTING DATE\n",
        "\n",
        "  first_listing_date = page_soup.find(class_ = \"card-footer__publish-date\")\n",
        "  print(\"PAGE NUMBER: \" + str(pageno))\n",
        "\n",
        "  print(first_listing_date.text)\n",
        "\n",
        "  # CHECK LISTING DATE IS NOT GREATER THAN 14\n",
        "\n",
        "  if \"14 days ago\" in first_listing_date.text:\n",
        "    listing_date_below_14 = False\n",
        "    break\n",
        "  \n",
        "  #  FOR LOOP THROUGH ALL LISTINGS ON THE PAGE\n",
        "\n",
        "  for i in page_soup.find_all(class_ = \"card__link\"):\n",
        "    \n",
        "    # GET LISTING URL, RESPONSE, SOUP\n",
        "    listing_url = \"https://www.propertyfinder.eg\" + i.get('href')\n",
        "    print(\"#############LISTING ON PAGE \" + str(pageno) + \"####################\")\n",
        "    print(\"LISTING URL: \"+listing_url)\n",
        "\n",
        "    listing_response = requests.get(listing_url, headers=HEADERS)\n",
        "    listing_soup = BeautifulSoup(listing_response.content)\n",
        "\n",
        "    # #####                                  #######\n",
        "    # #####  GET DATA FOR PROPERTY           ######\n",
        "    # #####                                  #######\n",
        "\n",
        "\n",
        "    # PROPERTY PRICE\n",
        "    try:\n",
        "      property_price = listing_soup.find(class_ = \"property-price__price\").text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\").replace(\",\", \"\").replace(\"EGP\", \"\")\n",
        "      print(\"PROPERTY PRICE: \" + property_price)\n",
        "    except:\n",
        "      property_price = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### PROPERTY PRICE\")\n",
        "\n",
        "\n",
        "    # PROPERTY TYPE\n",
        "    try:\n",
        "      property_facts = listing_soup.find_all(class_ = \"property-facts__value\")\n",
        "      property_type = property_facts[0].text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0/\\xa0\", \" / \").replace(\"+Maid\", \"\")\n",
        "      print(\"Type: \"+ property_type)\n",
        "    except:\n",
        "      property_facts = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### PROPERTY FACTS\")\n",
        "\n",
        "    # PROPERTY AREA\n",
        "\n",
        "    try:\n",
        "      property_area_sqft = property_facts[1].text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0/\\xa0\", \" / \").replace(\",\", \"\").split()[0].replace('sqft', '')\n",
        "      property_area_sqm =  property_facts[1].text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0/\\xa0\", \" / \").replace(\",\", \"\").split()[2].replace('sqm', '')\n",
        "      print(\"SQFT: \"+ property_area_sqft)\n",
        "      print(\"SQM: \" + property_area_sqm)\n",
        "    except:\n",
        "      property_area_sqft = None\n",
        "      property_area_sqm = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### PROPERTY AREA\")\n",
        "\n",
        "    # PROPERTY BEDROOMS\n",
        "    try:\n",
        "      property_bedrooms = property_facts[2].text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0/\\xa0\", \" / \").replace(\"+Maid\", \"\")\n",
        "      print(\"Bedrooms: \"+ property_bedrooms)\n",
        "    except:\n",
        "      property_bedrooms = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BEDROOMS\")\n",
        "\n",
        "    # PROPERTY BATHROOMS\n",
        "    try:\n",
        "      property_bathrooms = property_facts[3].text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0/\\xa0\", \" / \").replace(\"+Maid\", \"\")\n",
        "      print(\"Bathrooms: \"+ property_bathrooms)\n",
        "    except: \n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BATHROOMS\")\n",
        "      property_bathrooms = None\n",
        "\n",
        "\n",
        "    # PROPERTY ID\n",
        "    try:\n",
        "      property_id = listing_soup.find_all(class_ = 'property-page__legal-list-content')[0].text.replace(\"\\\\\", \"\").replace( \"\\n\", \"\").replace(\"\\n\", \"\")\n",
        "      print(\"ID: \"+ property_id)\n",
        "    except:\n",
        "      property_id = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### PROPERTY ID\")\n",
        "\n",
        "    # PROPERTY LISTING DATE\n",
        "    try:\n",
        "      property_listing_date = listing_soup.find_all(class_ = 'property-page__legal-list-content')[1].text\n",
        "      print(\"LISTING DATE: \" + property_listing_date)\n",
        "    except:\n",
        "      property_listing_date = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### LISTING DATE\")\n",
        "\n",
        "\n",
        "    # LOCATION\n",
        "    try:\n",
        "      property_location = list(listing_soup.find(class_ = \"property-location__detail-area\").children)[1].text\n",
        "      print(\"LOCATION: \"+ property_location)\n",
        "    except:\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### LOCATION\")\n",
        "      property_location = None\n",
        "\n",
        "\n",
        "    # DESCRIPTION\n",
        "    try:\n",
        "      property_desc = listing_soup.find(class_ =  \"property-description__text-trim\").text\n",
        "      print(\"PROPERTY DESCRIPTION: AVAILABLE\")\n",
        "    except:\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### DESCRIPTION\")\n",
        "      property_desc = None\n",
        "    \n",
        "\n",
        "\n",
        "    # AMENITIES\n",
        "\n",
        "    try:\n",
        "      property_amenities = listing_soup.find(class_ = 'property-amenities').text\n",
        "      print(\"AMENITIES: AVAILABLE\")\n",
        "    except:\n",
        "      property_amenities = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### AMENITIES\")\n",
        "      \n",
        "    # #####                                  #######\n",
        "    # #####  GET DATA FOR AGENT              ######\n",
        "    # #####                                  #######\n",
        "\n",
        "\n",
        "    # AGENT NAME\n",
        "    try:\n",
        "      agent_name = listing_soup.find(class_=\"text text--size3 property-agent__name\").text.replace(\"..\",\"\")\n",
        "      print(\"AGENT NAME: \"+ agent_name)\n",
        "    except:\n",
        "      agent_name = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### AGENT NAME\")\n",
        "\n",
        "\n",
        "    all_scripts = listing_soup.find_all('script')\n",
        "    script_string=str(all_scripts[15])\n",
        "    # AGENT PHONE\n",
        "    try:\n",
        "      agent_phone = \"+20\"+re.search(\"phone\\\",\\\"value\\\":\\\"\\+20(.{10})\", script_string).group(1)\n",
        "      print(\"AGENT PHONE: \"+ agent_phone)\n",
        "    except:\n",
        "      agent_phone = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### AGENT PHONE\")\n",
        "\n",
        "    # AGENT EMAIL\n",
        "    try:\n",
        "      agent_email =  re.search(\"email\\\",\\\"value\\\":\\\"(.{23})\", script_string).group(1)\n",
        "      print(\"AGENT EMAIL: \"+agent_email)\n",
        "    except:\n",
        "      agent_email = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### AGENT EMAIL\")\n",
        "\n",
        "    # AGENT WHATSAPP\n",
        "    try:\n",
        "      agent_whatsapp = \"+20\" + re.search(\"whatsapp\\\",\\\"value\\\":\\\"\\+20(.{10})\", script_string).group(1)\n",
        "      print(\"AGENT WHATSAPP: \"+ agent_whatsapp)\n",
        "    except:\n",
        "      agent_whatsapp = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### AGENT WHATSAPP\")\n",
        "        \n",
        "    # #####                                  #######\n",
        "    # #####  GET DATA FOR BROKER COMPANY     ######\n",
        "    # #####                                  #######\n",
        "\n",
        "    try:\n",
        "      broker_company_list = list(listing_soup.find(class_ = 'text text--size2 property-agent__position').children)\n",
        "    except:\n",
        "      broker_company_list = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER COMPANY LIST\")\n",
        "    # BROKER NAME\n",
        "    \n",
        "    try:\n",
        "      broker_name = broker_company_list[0].text.strip() # broker company name\n",
        "      print(\"BROKER NAME: \" + broker_name)\n",
        "    except:\n",
        "      broker_name = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER NAME\")\n",
        "\n",
        "    # BROKER no OF LISTINGS\n",
        "    broker_listings = None\n",
        "    try:\n",
        "      broker_listings = int(broker_company_list[1].text.strip().replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"properties\", \"\")) # broker company no of listings\n",
        "      print(\"BROKER LISTINGS: \"+ str(broker_listings))\n",
        "    except:\n",
        "      broker_listings = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER NO OF LISTINGS\")\n",
        "    \n",
        "\n",
        "    # GET BROKER COMPANY PAGE LINK\n",
        "    broker_company_link = \"\"\n",
        "    try:\n",
        "      for i in listing_soup.find(class_=\"property-agent__broker-image-area\"):\n",
        "        if i.get('href') != None:\n",
        "          broker_company_link = 'https://www.propertyfinder.eg' + str(i.get('href'))\n",
        "    except:\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER COMPANY PAGE LINK\")\n",
        "\n",
        "\n",
        "    # GET BROKER PAGE REQUEST AND SOUP\n",
        "\n",
        "    try:\n",
        "      broker_page =  requests.get(broker_company_link, headers=HEADERS)\n",
        "      broker_soup = BeautifulSoup(broker_page.content)\n",
        "    except:\n",
        "      broker_page = None\n",
        "      broker_soup = None\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER PAGE AND SOUP\")\n",
        "\n",
        "    # BROKER HEAD OFFICE ADDRESS\n",
        "    \n",
        "    try:\n",
        "      broker_address = broker_soup.find(class_ = 'bio-info__details').text.replace(\"Head office:\", \"\")\n",
        "      print(\"BROKER ADDRESS: \"+broker_address)\n",
        "    except:\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER ADDRESS\")\n",
        "      broker_address = None\n",
        "\n",
        "\n",
        "    # BROKER PHONE\n",
        "    \n",
        "    try:\n",
        "      broker_phone = broker_soup.find(class_ = 'button__phone-ltr').text\n",
        "      print(\"BROKER PHONE: \"+broker_phone)\n",
        "    except:\n",
        "      print(\"COULD NOT OBTAIN VALUE ######### BROKER PHONE\")\n",
        "      broker_phone = None\n",
        "\n",
        "    # #####                                   #######\n",
        "    # #####  GET DATA FOR DEVELOPMENT PROJECT ######\n",
        "    # #####                                   #######\n",
        "\n",
        "    # DEVELOPMENT PROJECT PAGE\n",
        "    \n",
        "# Find project page link\n",
        "\n",
        "\n",
        "   # TEST LISTING SOUP - LINK WITH A PROJECT\n",
        "    # listing_url = 'https://www.propertyfinder.eg/en/plp/buy/apartment-for-sale-cairo-shorouk-city-5th-district-cleopatra-palace-991757.html'\n",
        "    # listing_response = requests.get(listing_url, headers=HEADERS)\n",
        "    # listing_soup = BeautifulSoup(listing_response.content)\n",
        "\n",
        "\n",
        "    project_url = None\n",
        "    project_response = None\n",
        "    project_soup = None\n",
        "    project_name = None\n",
        "    project_location = None\n",
        "    project_head_office = None\n",
        "    project_total_units = None\n",
        "    project_status = None\n",
        "    project_photo = None\n",
        "\n",
        "    if listing_soup.find(class_ = 'property-project-details__title') != None:\n",
        "      property_list = list(listing_soup.find(class_=\"property-project-details__developer-box\").children)\n",
        "      property_list_2 = list(property_list[1].children)\n",
        "      project_url = 'https://www.propertyfinder.eg' + str(property_list_2[1].get('href'))\n",
        "\n",
        "      print(\"Project URL: \"+ project_url)\n",
        "\n",
        "\n",
        "      # GET SOUP OF PROJECT PAGE\n",
        "      project_response = requests.get(project_url, headers=HEADERS)\n",
        "      project_soup = BeautifulSoup(project_response.content)\n",
        "\n",
        "\n",
        "\n",
        "      # GET PROJECT NAME - listing page\n",
        "      try:\n",
        "        project_name = listing_soup.find(class_ = 'property-project-details__title').text\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "      # GET PROJECT LOCATION - listing page\n",
        "      try:\n",
        "        project_location = listing_soup.find(class_='property-project-details__location').text\n",
        "\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(\"COULD NOT OBTAIN VALUE ######### PROJECT LOCATION\")\n",
        "\n",
        "\n",
        "      # GET PROJECT STATUS - listing page\n",
        "\n",
        "      # --- use listing soup\n",
        "      try:\n",
        "        project_status = listing_soup.find_all(class_ = 'property-project-details__list-item-value')[3].text.strip()\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(\"PROJECT STATUS: \"+project_status)\n",
        "\n",
        "      # GET PROJECT PHOTO - listing page\n",
        "      try:\n",
        "        project_photo = listing_soup.find(class_ ='property-project-details-gallery__image-container-img').get('src')\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "      # PROJECT HEAD OFFICE - project page\n",
        "      try:\n",
        "        project_head_office = list(list(project_soup.find(class_ = \"bio-info__details\").children)[0].children)[1].text.strip()\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "          \n",
        "\n",
        "      # GET PROJECT TOTAL UNITS - project page\n",
        "      try:\n",
        "        project_total_units = project_soup.find_all(\"a\", { \"class\" : \"link\"})[1].text.replace(\" Properties\",\"\")\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "      \n",
        "      print(project_name) \n",
        "      print(project_location)\n",
        "      print(project_head_office)\n",
        "      print(project_total_units)\n",
        "      print(project_status)\n",
        "      print(project_photo)\n",
        "\n",
        "    else:\n",
        "      print(\"No Project Found\")\n",
        "\n",
        "\n",
        "    property_data.append({\n",
        "    \"id\": property_id,\n",
        "    \"price\": property_price,\n",
        "    \"area_sqft\": property_area_sqft,\n",
        "    \"area_sqm\": property_area_sqm,\n",
        "    \"bedrooms\": property_bedrooms,\n",
        "    \"bathrooms\": property_bathrooms,\n",
        "    \"date\": property_listing_date,\n",
        "    \"location\": property_location,\n",
        "    \"description\": property_desc,\n",
        "    \"amenities\": property_amenities,\n",
        "    \"agent_phone\": agent_phone,\n",
        "    \"project_name\": project_name\n",
        "    })\n",
        "    \n",
        "    agent_data.append({\n",
        "        \"name\": agent_name,\n",
        "        \"phone\": agent_phone,\n",
        "        \"email\": agent_email,\n",
        "        \"whatsapp\": agent_whatsapp,\n",
        "        \"broker_phone\": broker_phone\n",
        "    })\n",
        "\n",
        "    broker_data.append({\n",
        "        \"name\": broker_name,\n",
        "        \"listings\": broker_listings,\n",
        "        \"address\": broker_address,\n",
        "        \"phone\": broker_phone\n",
        "    })\n",
        "\n",
        "    project_data.append({\n",
        "        \"name\": project_name,\n",
        "        \"location\": project_location,\n",
        "        \"head_office\": project_head_office,\n",
        "        \"total_units\": project_total_units,\n",
        "        \"photo\": project_photo,\n",
        "        \"status\": project_status\n",
        "    })\n",
        "    \n",
        "    username = faker.name()\n",
        "    review_id = faker.ean()\n",
        "\n",
        "    user_data.append({\n",
        "        \"username\": username,\n",
        "        \"email\": faker.email(),\n",
        "        \"gender\": random.choices([\"M\",\"F\"]),\n",
        "        \"age\": random.randrange(18,65),\n",
        "        \"birthdate\": str(faker.date_of_birth()),\n",
        "        \"review_id\": review_id,\n",
        "        \"area_of_focus\": str(faker.word())\n",
        "    })\n",
        "    \n",
        "    review_data.append({\n",
        "        \"review_id\": review_id,\n",
        "        \"username\": username,\n",
        "        \"agent_phone_no\": agent_phone,\n",
        "        \"date\": str(faker.date_this_year())\n",
        "    })\n",
        "\n",
        "\n",
        "  property_table=pd.DataFrame(property_data)\n",
        "  agent_table = pd.DataFrame(agent_data)\n",
        "  broker_table = pd.DataFrame(broker_data)\n",
        "  project_table = pd.DataFrame(project_data)\n",
        "  user_table = pd.DataFrame(user_data)\n",
        "  review_table = pd.DataFrame(review_data)\n",
        "\n",
        "  print(property_table)\n",
        "  print(agent_table)\n",
        "  print(broker_table)\n",
        "  print(project_table)\n",
        "  print(user_table)\n",
        "  print(review_table)\n",
        "  \n",
        "\n",
        "  \n",
        "  pageno+=1\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5TgoW_40yQze"
      },
      "source": [
        "# **ASSUMPTIONS / CONSTRAINTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXKl8Dz_qp0D"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ASSUMPTIONS / CONSTRAINTS\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "* The reference of each listing effectively is unique and acts as an identifying primary key\n",
        "* No two projects have the same name, so name can be used as a project identifier\n",
        "* Amenities are contained in a single string, so it does not require a table to store it\n",
        "* \n",
        "\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X5hHhsna4D30",
        "5TgoW_40yQze"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
